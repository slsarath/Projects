#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Hybrid 3-class classifier (Complaint, Concern, Neutral) for call transcripts.

Now supports CSV and Excel:
- Input auto-detected by extension (.csv, .xlsx, .xls)
- Optional SHEET_NAME for Excel
- Inference output writes .xlsx if output filename ends with .xlsx (otherwise .csv)

Pipeline
--------
1) Build data-driven keyword clusters from TRAIN split (TF-IDF n-grams expanded by embedding similarity).
2) Compute pooled sentence embeddings for each transcript (chunked).
3) Create rule features (loudness, AWS sentiment -5..+5, keyword hits, semantic sims).
4) Train multinomial Logistic Regression on fused features.
5) Blend ML probabilities with rule one-hots for the final decision.
6) Save artifacts + inference function.

Requires: pandas, numpy, scikit-learn, sentence-transformers, openpyxl (for Excel).
"""

# =========================
# Imports & Config
# =========================
import os
import re
import json
import joblib
import numpy as np
import pandas as pd
from typing import List, Tuple, Dict, Optional

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

from sentence_transformers import SentenceTransformer

# ----- Paths / Columns -----
INPUT_FILE  = "input_transcripts.xlsx"   # <<< CHANGE HERE (xlsx/xls/csv)
SHEET_NAME  = None                       # <<< CHANGE HERE if your Excel has a specific sheet (e.g., "Sheet1")
OUTPUT_DIR  = "artifacts_hybrid_v1"      # <<< CHANGE HERE
os.makedirs(OUTPUT_DIR, exist_ok=True)

COL_TEXT_CUST   = "customer_light"       # <<< CHANGE HERE if needed
COL_TEXT_FULL   = "full_light"           # optional fallback
COL_LABEL       = "materiality"          # values: NEUTRAL / CONCERN / COMPLAINT (script normalizes)
COL_LOUDNESS    = "loudnessscore"
COL_SENTIMENT   = "Max negative customer score"  # AWS Contact Lens (-5..+5)

# ----- Model / thresholds -----
RANDOM_SEED     = 42
EMBED_MODEL     = "sentence-transformers/all-mpnet-base-v2"  # <<< CHANGE if you prefer
MAX_CHARS_CHUNK = 1000

LOUD_HIGH_TH     = 96.0
SENT_STRONG_NEG  = -3.0
SENT_MOD_NEG_MAX = 0.0
NEU_POS_TH       = 0.5

TFIDF_NGRAM      = (1, 3)
TFIDF_MAX_FEAT   = 30000
TOP_K_CANDIDATES = 4000
TOP_K_PER_CLASS  = 200
SIM_THRESHOLD    = 0.35

ALPHA_RULE_BLEND = 0.55

LABEL2ID = {"NEUTRAL": 0, "CONCERN": 1, "COMPLAINT": 2}
ID2LABEL = {v: k for k, v in LABEL2ID.items()}

# =========================
# IO helpers (CSV/Excel)
# =========================
def read_table(path: str, sheet: Optional[str] = None) -> pd.DataFrame:
    low = path.lower()
    if low.endswith(".csv"):
        return pd.read_csv(path)
    if low.endswith(".xlsx") or low.endswith(".xls"):
        # requires openpyxl (xlsx) or xlrd (xls). Prefer openpyxl engine.
        return pd.read_excel(path, sheet_name=sheet, engine="openpyxl")
    raise ValueError(f"Unsupported file type: {path}")

def write_table(df: pd.DataFrame, path: str) -> None:
    low = path.lower()
    if low.endswith(".xlsx") or low.endswith(".xls"):
        df.to_excel(path, index=False, engine="openpyxl")
    elif low.endswith(".csv"):
        df.to_csv(path, index=False)
    else:
        # default to CSV if no extension recognized
        df.to_csv(path if "." in path else path + ".csv", index=False)

# =========================
# Minimal text helpers
# =========================
def chunk_text(text: str, max_chars: int = MAX_CHARS_CHUNK) -> List[str]:
    t = (text or "").strip()
    if not t:
        return []
    return [t[i:i+max_chars] for i in range(0, len(t), max_chars)]

def text_series(df: pd.DataFrame) -> pd.Series:
    for c in (COL_TEXT_CUST, COL_TEXT_FULL):
        if c in df.columns:
            s = df[c].fillna("").astype(str)
            if s.str.strip().str.len().sum() > 0:
                return s
    raise KeyError("No suitable text column found (need customer_light or full_light).")

def normalize_labels_inplace(df: pd.DataFrame, label_col: str = COL_LABEL) -> None:
    df[label_col] = (
        df[label_col]
        .fillna("NEUTRAL")
        .astype(str)
        .str.upper()
        .str.strip()
        .replace({
            "COMPLAINTS": "COMPLAINT",
            "CONCERNS": "CONCERN",
            "NULL": "NEUTRAL",
            "N/A": "NEUTRAL",
            "": "NEUTRAL"
        })
    )

def prepare_labels(df: pd.DataFrame, label_col: str = COL_LABEL) -> np.ndarray:
    y = (
        df[label_col]
        .fillna("NEUTRAL")
        .astype(str)
        .str.upper()
        .str.strip()
        .replace({
            "COMPLAINTS": "COMPLAINT",
            "CONCERNS": "CONCERN",
            "NULL": "NEUTRAL",
            "N/A": "NEUTRAL",
            "": "NEUTRAL"
        })
    )
    return y.map(LABEL2ID).values

# =========================
# Keyword discovery
# =========================
from sklearn.feature_extraction.text import TfidfVectorizer

def build_candidate_phrases(texts: List[str]) -> List[str]:
    tfidf = TfidfVectorizer(
        max_features=TFIDF_MAX_FEAT,
        ngram_range=TFIDF_NGRAM,
        token_pattern=r"(?u)\b\w+\b",
        lowercase=True,
        stop_words="english",
        min_df=3
    )
    X = tfidf.fit_transform(texts)
    vocab = np.array(tfidf.get_feature_names_out())
    scores = np.asarray(X.sum(axis=0)).ravel()
    idx = np.argsort(scores)[::-1]
    top = vocab[idx][:TOP_K_CANDIDATES]
    cleaned = []
    for p in top:
        if len(p) < 3:
            continue
        tokens = [w for w in p.split() if w not in ENGLISH_STOP_WORDS]
        if not tokens:
            continue
        cleaned.append(" ".join(tokens))
    return cleaned[:TOP_K_CANDIDATES]

from sentence_transformers import SentenceTransformer

def expand_keywords_by_similarity(
    model: SentenceTransformer,
    candidates: List[str],
    seed_phrases: List[str],
    top_k: int = TOP_K_PER_CLASS
) -> Tuple[List[str], np.ndarray]:
    if not candidates:
        return [], np.zeros((0, model.get_sentence_embedding_dimension()), dtype=np.float32)
    seed_embs = model.encode(seed_phrases, convert_to_numpy=True, normalize_embeddings=True, batch_size=64)
    centroid = seed_embs.mean(axis=0)
    cand_embs = model.encode(candidates, convert_to_numpy=True, normalize_embeddings=True, batch_size=256)
    sims = cand_embs @ centroid
    top_idx = np.argsort(sims)[::-1][:top_k]
    return [candidates[i] for i in top_idx], cand_embs[top_idx]

# =========================
# Embeddings & Features
# =========================
def embed_transcript(model: SentenceTransformer, text: str) -> np.ndarray:
    chunks = chunk_text(text)
    if not chunks:
        return np.zeros(model.get_sentence_embedding_dimension(), dtype=np.float32)
    embs = model.encode(chunks, convert_to_numpy=True, normalize_embeddings=True, batch_size=32)
    return embs.mean(axis=0).astype(np.float32)

def build_feature_matrix(
    model: SentenceTransformer,
    df: pd.DataFrame,
    comp_kw: List[str],
    comp_kw_emb: np.ndarray,
    con_kw: List[str],
    con_kw_emb: np.ndarray,
    scaler: Optional[MinMaxScaler] = None,
    fit_scaler: bool = False
) -> Tuple[np.ndarray, np.ndarray, MinMaxScaler]:
    texts = text_series(df).tolist()
    N = len(texts)

    # Embeddings
    emb_list = [embed_transcript(model, t) for t in texts]
    E = np.vstack(emb_list)  # (N, d)

    # Keyword counts
    def count_hits(s: str, kws: List[str]) -> int:
        s_low = s.lower()
        return sum(1 for k in kws if k in s_low)

    comp_counts = np.array([count_hits(t, comp_kw) for t in texts], dtype=np.float32)
    con_counts  = np.array([count_hits(t, con_kw)  for t in texts], dtype=np.float32)

    # Semantic similarity to keyword centroids
    def centroid(embs: np.ndarray) -> np.ndarray:
        if embs.size == 0:
            return np.zeros(E.shape[1], dtype=np.float32)
        return embs.mean(axis=0).astype(np.float32)

    comp_centroid = centroid(comp_kw_emb)
    con_centroid  = centroid(con_kw_emb)

    def safe_cosine_to_centroid(mat: np.ndarray, c: np.ndarray) -> np.ndarray:
        if np.allclose(c, 0.0):
            return np.zeros((mat.shape[0],), dtype=np.float32)
        denom = (np.linalg.norm(mat, axis=1) * (np.linalg.norm(c) + 1e-12) + 1e-12)
        sims = (mat @ c) / denom
        return np.nan_to_num(sims, nan=0.0).astype(np.float32)

    sims_comp = safe_cosine_to_centroid(E, comp_centroid)
    sims_con  = safe_cosine_to_centroid(E, con_centroid)

    # Numeric inputs
    loud = df.get(COL_LOUDNESS, pd.Series([0]*N)).astype(float).values.astype(np.float32)
    sent = df.get(COL_SENTIMENT, pd.Series([0]*N)).astype(float).values.astype(np.float32)

    # Rule flags
    rule_complaint = ((loud > LOUD_HIGH_TH) & (sent <= SENT_STRONG_NEG) &
                      ((comp_counts > 0) | (sims_comp >= SIM_THRESHOLD))).astype(np.float32)
    rule_concern   = ((sent > SENT_STRONG_NEG) & (sent <= SENT_MOD_NEG_MAX) &
                      ((con_counts > 0) | (sims_con >= SIM_THRESHOLD))).astype(np.float32)
    rule_neutral   = ((sent >= NEU_POS_TH) &
                      (comp_counts + con_counts == 0) &
                      (sims_comp < SIM_THRESHOLD) &
                      (sims_con  < SIM_THRESHOLD)).astype(np.float32)

    # Scale numeric block
    numeric = np.vstack([loud, sent, comp_counts, con_counts, sims_comp, sims_con]).T  # (N, 6)
    if scaler is None:
        scaler = MinMaxScaler()
        fit_scaler = True
    if fit_scaler:
        scaler.fit(numeric)
    numeric_scaled = scaler.transform(numeric).astype(np.float32)

    # Fuse
    X = np.hstack([
        E,
        numeric_scaled,
        rule_complaint.reshape(-1, 1),
        rule_concern.reshape(-1, 1),
        rule_neutral.reshape(-1, 1)
    ]).astype(np.float32)

    meta_cols = np.array([
        "loudness_scaled", "sentiment_scaled",
        "complaint_kw_count_scaled", "concern_kw_count_scaled",
        "sim_comp_scaled", "sim_con_scaled",
        "rule_complaint", "rule_concern", "rule_neutral"
    ])
    return X, meta_cols, scaler

def build_rule_onehot(rule_neu: np.ndarray, rule_con: np.ndarray, rule_comp: np.ndarray) -> np.ndarray:
    return np.vstack([rule_neu, rule_con, rule_comp]).T.astype(np.float32)

def blended_predict_proba(clf: LogisticRegression, X: np.ndarray, rule_flags: np.ndarray, alpha: float = ALPHA_RULE_BLEND) -> np.ndarray:
    proba = clf.predict_proba(X)
    rf = rule_flags.astype(np.float32)
    blended = proba + alpha * rf
    blended = blended / blended.sum(axis=1, keepdims=True)
    return blended

# =========================
# Training / Evaluation
# =========================
def main():
    # Load table (CSV or Excel)
    df = read_table(INPUT_FILE, sheet=SHEET_NAME)

    # Basic checks
    for col in (COL_LABEL, COL_TEXT_CUST, COL_SENTIMENT, COL_LOUDNESS):
        if col not in df.columns:
            raise KeyError(f"Missing required column: {col}")

    # Normalize labels, filter valid
    normalize_labels_inplace(df, COL_LABEL)
    df = df[df[COL_LABEL].isin(LABEL2ID.keys())].reset_index(drop=True)

    # Stratified split 70/15/15
    train_df, test_df = train_test_split(
        df, test_size=0.15, random_state=RANDOM_SEED, stratify=df[COL_LABEL]
    )
    train_df, val_df  = train_test_split(
        train_df, test_size=0.1765, random_state=RANDOM_SEED, stratify=train_df[COL_LABEL]
    )

    # Show label distribution
    for name, d in [("train", train_df), ("val", val_df), ("test", test_df)]:
        print(name, d[COL_LABEL].value_counts().to_dict())

    # Embedding model
    model = SentenceTransformer(EMBED_MODEL)

    # Data-driven keywords from TRAIN
    train_texts = text_series(train_df).tolist()

    complaint_seeds = [
        "complaint", "issue", "problem", "not satisfied", "unhappy",
        "refund", "escalate", "raise a complaint", "poor service",
        "unacceptable", "bad experience", "charged wrongly", "overcharged",
        "want to cancel", "manager escalation"
    ]
    concern_seeds = [
        "concern", "worry", "doubt", "not sure", "need clarification",
        "query", "question", "unsure", "need help", "confused"
    ]

    candidates = build_candidate_phrases(train_texts)
    comp_kw, comp_kw_emb = expand_keywords_by_similarity(model, candidates, complaint_seeds, TOP_K_PER_CLASS)
    con_kw,  con_kw_emb  = expand_keywords_by_similarity(model, candidates, concern_seeds,   TOP_K_PER_CLASS)

    # Persist keyword lists
    with open(os.path.join(OUTPUT_DIR, "complaint_keywords.json"), "w") as f:
        json.dump(comp_kw, f, indent=2)
    with open(os.path.join(OUTPUT_DIR, "concern_keywords.json"), "w") as f:
        json.dump(con_kw, f, indent=2)

    # Features
    X_train, meta_cols, scaler = build_feature_matrix(model, train_df, comp_kw, comp_kw_emb, con_kw, con_kw_emb, scaler=None, fit_scaler=True)
    X_val,   _,        _      = build_feature_matrix(model, val_df,   comp_kw, comp_kw_emb, con_kw, con_kw_emb, scaler=scaler, fit_scaler=False)
    X_test,  _,        _      = build_feature_matrix(model, test_df,  comp_kw, comp_kw_emb, con_kw, con_kw_emb, scaler=scaler, fit_scaler=False)

    y_train = prepare_labels(train_df)
    y_val   = prepare_labels(val_df)
    y_test  = prepare_labels(test_df)

    # Rule flags from fused X (last 3 columns)
    def split_rule_flags(X: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        rule_comp = X[:, -3]
        rule_con  = X[:, -2]
        rule_neu  = X[:, -1]
        return rule_neu, rule_con, rule_comp

    rneu_va, rcon_va, rcomp_va = split_rule_flags(X_val)
    rneu_te, rcon_te, rcomp_te = split_rule_flags(X_test)

    # Train classifier
    clf = LogisticRegression(
        max_iter=1500,
        class_weight="balanced",
        multi_class="auto",
        solver="lbfgs",
        random_state=RANDOM_SEED
    )
    clf.fit(X_train, y_train)

    # Pure ML
    print("\n=== Pure ML (no blending) ===")
    y_pred_val = clf.predict(X_val)
    print("Validation:")
    print(classification_report(
        y_val, y_pred_val,
        labels=[0,1,2],
        target_names=["NEUTRAL","CONCERN","COMPLAINT"],
        zero_division=0
    ))
    y_pred_tst = clf.predict(X_test)
    print("Test:")
    print(classification_report(
        y_test, y_pred_tst,
        labels=[0,1,2],
        target_names=["NEUTRAL","CONCERN","COMPLAINT"],
        zero_division=0
    ))

    # Hybrid (blend rules + ML)
    print("\n=== Hybrid (ML + rule blending) ===")
    rule_onehot_val = build_rule_onehot(rneu_va, rcon_va, rcomp_va)
    rule_onehot_tst = build_rule_onehot(rneu_te, rcon_te, rcomp_te)

    proba_val_blend = blended_predict_proba(clf, X_val, rule_onehot_val, alpha=ALPHA_RULE_BLEND)
    proba_tst_blend = blended_predict_proba(clf, X_test, rule_onehot_tst, alpha=ALPHA_RULE_BLEND)

    y_pred_val_blend = np.argmax(proba_val_blend, axis=1)
    y_pred_tst_blend = np.argmax(proba_tst_blend, axis=1)

    print("Validation:")
    print(classification_report(
        y_val, y_pred_val_blend,
        labels=[0,1,2],
        target_names=["NEUTRAL","CONCERN","COMPLAINT"],
        zero_division=0
    ))
    print("Test:")
    print(classification_report(
        y_test, y_pred_tst_blend,
        labels=[0,1,2],
        target_names=["NEUTRAL","CONCERN","COMPLAINT"],
        zero_division=0
    ))

    # Save artifacts
    joblib.dump(clf, os.path.join(OUTPUT_DIR, "hybrid_logreg.joblib"))
    joblib.dump(scaler, os.path.join(OUTPUT_DIR, "numeric_scaler.joblib"))
    with open(os.path.join(OUTPUT_DIR, "meta_cols.json"), "w") as f:
        json.dump({"meta_cols": meta_cols.tolist()}, f)
    with open(os.path.join(OUTPUT_DIR, "embed_model.txt"), "w") as f:
        f.write(EMBED_MODEL)
    with open(os.path.join(OUTPUT_DIR, "label_mapping.json"), "w") as f:
        json.dump({"LABEL2ID": LABEL2ID, "ID2LABEL": ID2LABEL}, f, indent=2)

    print(f"\nArtifacts saved to: {OUTPUT_DIR}")

# =========================
# Inference (batch)
# =========================
def inference(input_path: str,
              artifacts_dir: str = OUTPUT_DIR,
              output_path: str = "predictions_output.xlsx",  # write Excel by default
              blend_with_rules: bool = True,
              alpha: float = ALPHA_RULE_BLEND,
              sheet: Optional[str] = None) -> pd.DataFrame:
    df_new = read_table(input_path, sheet=sheet)
    # labels may be absent; normalize anyway for consistency
    if COL_LABEL in df_new.columns:
        normalize_labels_inplace(df_new, COL_LABEL)

    # Load artifacts
    clf = joblib.load(os.path.join(artifacts_dir, "hybrid_logreg.joblib"))
    scaler = joblib.load(os.path.join(artifacts_dir, "numeric_scaler.joblib"))
    with open(os.path.join(artifacts_dir, "embed_model.txt"), "r") as f:
        emb_name = f.read().strip()
    model = SentenceTransformer(emb_name)

    with open(os.path.join(artifacts_dir, "complaint_keywords.json"), "r") as f:
        comp_kw = json.load(f)
    with open(os.path.join(artifacts_dir, "concern_keywords.json"), "r") as f:
        con_kw = json.load(f)

    # Recompute keyword centroid embeddings (fast enough)
    cand = comp_kw + con_kw
    if cand:
        all_embs = model.encode(cand, convert_to_numpy=True, normalize_embeddings=True, batch_size=256)
        comp_kw_emb = all_embs[:len(comp_kw)]
        con_kw_emb  = all_embs[len(comp_kw):]
    else:
        comp_kw_emb = np.zeros((0, model.get_sentence_embedding_dimension()), dtype=np.float32)
        con_kw_emb  = np.zeros((0, model.get_sentence_embedding_dimension()), dtype=np.float32)

    # Features
    X_new, _, _ = build_feature_matrix(model, df_new, comp_kw, comp_kw_emb, con_kw, con_kw_emb, scaler=scaler, fit_scaler=False)

    # Predict
    proba_ml = clf.predict_proba(X_new)
    if blend_with_rules:
        rule_comp = X_new[:, -3]
        rule_con  = X_new[:, -2]
        rule_neu  = X_new[:, -1]
        rule_onehot = build_rule_onehot(rule_neu, rule_con, rule_comp)
        proba = blended_predict_proba(clf, X_new, rule_onehot, alpha=alpha)
    else:
        proba = proba_ml

    y_hat = np.argmax(proba, axis=1)
    preds = [ID2LABEL[i] for i in y_hat]

    # Output
    df_new["pred_class"]        = preds
    df_new["proba_NEUTRAL"]     = proba[:, 0]
    df_new["proba_CONCERN"]     = proba[:, 1]
    df_new["proba_COMPLAINT"]   = proba[:, 2]

    write_table(df_new, output_path)
    print(f"Saved predictions to: {output_path}")
    return df_new

# =========================
# Entrypoint
# =========================
if __name__ == "__main__":
    main()
    # Example inference calls:
    # inference("unseen_calls.xlsx", artifacts_dir=OUTPUT_DIR, output_path="unseen_predictions.xlsx", sheet="Sheet1")
    # inference("unseen_calls.csv", artifacts_dir=OUTPUT_DIR, output_path="unseen_predictions.csv")
