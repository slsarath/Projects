# Modelling.py

import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE

# =====================================================
# 1. Load dataset
# =====================================================
def load_data(path="transcripts.csv"):
    df = pd.read_csv(path)

    # Drop rows where label is missing
    df = df.dropna(subset=["Materiality"])
    df["Materiality"] = df["Materiality"].astype(str)

    return df


# =====================================================
# 2. Prepare features
# =====================================================
def prepare_features(df, label_col="Materiality"):
    """
    Prepares X, y for modeling:
      - Separates numeric and categorical features
      - One-hot encodes categoricals
    """
    y = df[label_col]

    # Drop IDs or text cols not needed in baseline model
    drop_cols = [label_col, "call_id", "transcript", "clean_customer_only"]
    X = df.drop(columns=[c for c in drop_cols if c in df.columns])

    # Separate feature types
    numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()
    categorical_features = X.select_dtypes(exclude=[np.number]).columns.tolist()

    print("Numeric features:", numeric_features)
    print("Categorical features:", categorical_features)

    # Column transformer for preprocessing
    preprocessor = ColumnTransformer(
        transformers=[
            ("num", "passthrough", numeric_features),
            ("cat", OneHotEncoder(handle_unknown="ignore"), categorical_features)
        ]
    )

    return X, y, preprocessor


# =====================================================
# 3. Handle imbalance with SMOTE
# =====================================================
def balance_data(X, y):
    smote = SMOTE(random_state=42)
    X_bal, y_bal = smote.fit_resample(X, y)
    return X_bal, y_bal


# =====================================================
# 4. Train models (Logistic Regression + Random Forest)
# =====================================================
def train_models(X_train, y_train, X_bal, y_bal, class_weight_dict, preprocessor):
    models = {
        "Logistic Regression": Pipeline([
            ("preprocessor", preprocessor),
            ("clf", LogisticRegression(max_iter=1000, class_weight=class_weight_dict))
        ]),
        "Random Forest": Pipeline([
            ("preprocessor", preprocessor),
            ("clf", RandomForestClassifier(class_weight=class_weight_dict, random_state=42))
        ])
    }

    trained_models = {}
    for name, model in models.items():
        print(f"\nTraining {name}...")
        model.fit(X_train, y_train)
        trained_models[name] = model

    return trained_models


# =====================================================
# 5. Evaluate models
# =====================================================
def evaluate_models(models, X_test, y_test):
    for name, model in models.items():
        print(f"\nEvaluating {name}...")
        y_pred = model.predict(X_test)
        print(confusion_matrix(y_test, y_pred))
        print(classification_report(y_test, y_pred))


# =====================================================
# 6. Main pipeline
# =====================================================
def main():
    # Load data
    df = load_data("transcripts.csv")

    # Prepare features
    X, y, preprocessor = prepare_features(df, label_col="Materiality")

    # Train/test split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, stratify=y, random_state=42
    )

    # Handle imbalance
    X_bal, y_bal = balance_data(X_train, y_train)

    # Class weights (for imbalance handling)
    class_weight_dict = y_train.value_counts(normalize=True).to_dict()
    class_weight_dict = {k: 1/v for k, v in class_weight_dict.items()}  # inverse frequency

    print("Class weights:", class_weight_dict)

    # Train models
    models = train_models(X_train, y_train, X_bal, y_bal, class_weight_dict, preprocessor)

    # Evaluate
    evaluate_models(models, X_test, y_test)


if __name__ == "__main__":
    main()